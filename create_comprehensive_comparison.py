#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¶œåˆèšé¡ç®—æ³•æ¯”è¼ƒå’Œåˆ†æè…³æœ¬
"""

import pandas as pd
import numpy as np
import os

def create_comprehensive_comparison():
    """å‰µå»ºç¶œåˆæ¯”è¼ƒè¡¨æ ¼"""
    
    # è®€å–èšé¡åˆ†æå ±å‘Šï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    report_file = "clustering_analysis_report.txt"
    performance_metrics = {}
    
    if os.path.exists(report_file):
        print("è®€å–èšé¡åˆ†æå ±å‘Š...")
        with open(report_file, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # è§£æå ±å‘Šä¸­çš„æ€§èƒ½æŒ‡æ¨™
        lines = content.split('\n')
        current_algorithm = None
        
        for line in lines:
            line = line.strip()
            if line.endswith(':') and line.replace(':', '').upper() in ['KMEANS', 'DBSCAN', 'HDBSCAN', 'SPECTRAL', 'GMM', 'AGGLOMERATIVE']:
                current_algorithm = line.replace(':', '').lower()
                performance_metrics[current_algorithm] = {}
            elif current_algorithm and '  - ' in line:
                if 'Silhouette Score:' in line:
                    score = line.split(':')[1].strip()
                    performance_metrics[current_algorithm]['silhouette'] = score
                elif 'åŸ·è¡Œæ™‚é–“:' in line:
                    time_str = line.split(':')[1].strip().replace(' ç§’', '')
                    performance_metrics[current_algorithm]['execution_time'] = time_str
                elif 'Calinski-Harabasz Score:' in line:
                    score = line.split(':')[1].strip()
                    performance_metrics[current_algorithm]['calinski_harabasz'] = score
                elif 'Davies-Bouldin Score:' in line:
                    score = line.split(':')[1].strip()
                    performance_metrics[current_algorithm]['davies_bouldin'] = score
    
    # åˆ†æèšé¡åˆ†ä½ˆ
    algorithms = ['kmeans', 'dbscan', 'hdbscan', 'spectral', 'gmm', 'agglomerative']
    comparison_data = []
    
    for alg in algorithms:
        filename = f'{alg}_submission.csv'
        if os.path.exists(filename):
            # è®€å–çµæœ
            df = pd.read_csv(filename)
            label_counts = df['label'].value_counts().sort_index()
            
            # åŸºæœ¬çµ±è¨ˆ
            n_clusters = len(label_counts)
            total_samples = len(df)
            max_cluster_size = label_counts.max()
            min_cluster_size = label_counts.min()
            std_cluster_size = label_counts.std()
            imbalance_ratio = max_cluster_size / min_cluster_size if min_cluster_size > 0 else float('inf')
            
            # å¾å ±å‘Šè®€å–æ€§èƒ½æŒ‡æ¨™
            metrics = performance_metrics.get(alg, {})
            
            # è¨ˆç®—å¹³è¡¡åº¦è©•ç´š
            if imbalance_ratio < 2:
                balance_grade = "å„ª"
                balance_score = 5
            elif imbalance_ratio < 5:
                balance_grade = "è‰¯"
                balance_score = 4
            elif imbalance_ratio < 20:
                balance_grade = "ä¸­"
                balance_score = 3
            elif imbalance_ratio < 100:
                balance_grade = "å·®"
                balance_score = 2
            else:
                balance_grade = "æ¥µå·®"
                balance_score = 1
            
            # è¨ˆç®—èšé¡æ•¸è©•ç´šï¼ˆæ ¹æ“šæ•¸æ“šå¤§å°ï¼Œåˆç†çš„èšé¡æ•¸ï¼‰
            if 5 <= n_clusters <= 15:
                cluster_grade = "å„ª"
                cluster_score = 5
            elif 3 <= n_clusters <= 20:
                cluster_grade = "è‰¯" 
                cluster_score = 4
            elif 2 <= n_clusters <= 30:
                cluster_grade = "ä¸­"
                cluster_score = 3
            else:
                cluster_grade = "å·®"
                cluster_score = 2
            
            # ç¶œåˆè©•åˆ†ï¼ˆå¹³è¡¡åº¦ä½”50%ï¼Œèšé¡æ•¸é©ç•¶æ€§ä½”20%ï¼ŒSilhouetteä½”30%ï¼‰
            silhouette_score = float(metrics.get('silhouette', '0'))
            if silhouette_score > 0.5:
                silhouette_grade = 5
            elif silhouette_score > 0.3:
                silhouette_grade = 4
            elif silhouette_score > 0.1:
                silhouette_grade = 3
            elif silhouette_score > 0:
                silhouette_grade = 2
            else:
                silhouette_grade = 1
            
            overall_score = balance_score * 0.5 + cluster_score * 0.2 + silhouette_grade * 0.3
            
            comparison_data.append({
                'ç®—æ³•': alg.upper(),
                'èšé¡æ•¸': n_clusters,
                'æœ€å¤§/æœ€å°æ¯”ä¾‹': f"{imbalance_ratio:.1f}" if imbalance_ratio != float('inf') else "âˆ",
                'å¹³è¡¡åº¦': balance_grade,
                'Silhouetteåˆ†æ•¸': metrics.get('silhouette', 'N/A'),
                'Calinski-Harabasz': metrics.get('calinski_harabasz', 'N/A'),
                'Davies-Bouldin': metrics.get('davies_bouldin', 'N/A'),
                'åŸ·è¡Œæ™‚é–“(ç§’)': metrics.get('execution_time', 'N/A'),
                'ç¶œåˆè©•åˆ†': f"{overall_score:.2f}",
                'æ¨è–¦åº¦': "â˜…â˜…â˜…â˜…â˜…" if overall_score >= 4 else 
                         "â˜…â˜…â˜…â˜…â˜†" if overall_score >= 3.5 else
                         "â˜…â˜…â˜…â˜†â˜†" if overall_score >= 3 else
                         "â˜…â˜…â˜†â˜†â˜†" if overall_score >= 2 else "â˜…â˜†â˜†â˜†â˜†"
            })
    
    # å‰µå»ºDataFrameä¸¦æ’åº
    comparison_df = pd.DataFrame(comparison_data)
    comparison_df = comparison_df.sort_values('ç¶œåˆè©•åˆ†', ascending=False)
    
    return comparison_df

def generate_recommendations(comparison_df):
    """ç”Ÿæˆç®—æ³•æ¨è–¦"""
    print("\n" + "="*80)
    print("ğŸ¯ ç®—æ³•æ¨è–¦å’Œåˆ†æ")
    print("="*80)
    
    best_algorithm = comparison_df.iloc[0]
    worst_algorithm = comparison_df.iloc[-1]
    
    print(f"ğŸ† æœ€ä½³ç®—æ³•: {best_algorithm['ç®—æ³•']}")
    print(f"   - ç¶œåˆè©•åˆ†: {best_algorithm['ç¶œåˆè©•åˆ†']}")
    print(f"   - èšé¡æ•¸: {best_algorithm['èšé¡æ•¸']}")
    print(f"   - å¹³è¡¡åº¦: {best_algorithm['å¹³è¡¡åº¦']}")
    print(f"   - Silhouetteåˆ†æ•¸: {best_algorithm['Silhouetteåˆ†æ•¸']}")
    
    print(f"\nâŒ è¡¨ç¾æœ€å·®ç®—æ³•: {worst_algorithm['ç®—æ³•']}")
    print(f"   - ç¶œåˆè©•åˆ†: {worst_algorithm['ç¶œåˆè©•åˆ†']}")
    print(f"   - ä¸»è¦å•é¡Œ: å¹³è¡¡åº¦{worst_algorithm['å¹³è¡¡åº¦']}ï¼Œæ¯”ä¾‹{worst_algorithm['æœ€å¤§/æœ€å°æ¯”ä¾‹']}")
    
    print(f"\nğŸ“Š å„ç®—æ³•å•é¡Œåˆ†æ:")
    for _, row in comparison_df.iterrows():
        alg = row['ç®—æ³•']
        issues = []
        
        if row['å¹³è¡¡åº¦'] in ['å·®', 'æ¥µå·®']:
            issues.append(f"èšé¡ä¸å¹³è¡¡({row['æœ€å¤§/æœ€å°æ¯”ä¾‹']})")
        
        if row['èšé¡æ•¸'] < 3:
            issues.append("èšé¡æ•¸éå°‘")
        elif row['èšé¡æ•¸'] > 20:
            issues.append("èšé¡æ•¸éå¤š")
        
        try:
            silhouette = float(row['Silhouetteåˆ†æ•¸'])
            if silhouette < 0.2:
                issues.append(f"Silhouetteåˆ†æ•¸éä½({silhouette:.3f})")
        except:
            pass
        
        if issues:
            print(f"   {alg}: {', '.join(issues)}")
        else:
            print(f"   {alg}: è¡¨ç¾è‰¯å¥½")
    
    print(f"\nğŸ’¡ æ”¹é€²å»ºè­°:")
    
    # é‡å°å±¤æ¬¡èšé¡çš„ç‰¹åˆ¥å»ºè­°
    agg_row = comparison_df[comparison_df['ç®—æ³•'] == 'AGGLOMERATIVE']
    if not agg_row.empty and agg_row.iloc[0]['å¹³è¡¡åº¦'] == 'æ¥µå·®':
        print(f"   ğŸ”§ å±¤æ¬¡èšé¡ä¿®å¾©å»ºè­°:")
        print(f"      1. ä½¿ç”¨ä¸åŒçš„é€£æ¥æ–¹æ³• (ward, complete, average)")
        print(f"      2. èª¿æ•´èšé¡æ•¸ (å˜—è©¦3-10å€‹èšé¡)")
        print(f"      3. è€ƒæ…®è³‡æ–™é è™•ç† (é™ç¶­ã€ç‰¹å¾µé¸æ“‡)")
        print(f"      4. ä½¿ç”¨æ¨£æœ¬æ•¸æ“šé€²è¡Œåƒæ•¸èª¿å„ª")
    
    # é‡å°DBSCANçš„å»ºè­°
    dbscan_row = comparison_df[comparison_df['ç®—æ³•'] == 'DBSCAN']
    if not dbscan_row.empty and dbscan_row.iloc[0]['å¹³è¡¡åº¦'] == 'æ¥µå·®':
        print(f"   ğŸ”§ DBSCANä¿®å¾©å»ºè­°:")
        print(f"      1. èª¿æ•´epsåƒæ•¸ (å˜—è©¦0.1-2.0)")
        print(f"      2. èª¿æ•´min_samplesåƒæ•¸ (å˜—è©¦3-20)")
        print(f"      3. ä½¿ç”¨æ¨™æº–åŒ–æˆ–æ­£è¦åŒ–çš„è³‡æ–™")
    
    print(f"\nâœ… å»ºè­°ä½¿ç”¨é †åº:")
    for i, (_, row) in enumerate(comparison_df.iterrows(), 1):
        print(f"   {i}. {row['ç®—æ³•']} - {row['æ¨è–¦åº¦']} (è©•åˆ†: {row['ç¶œåˆè©•åˆ†']})")

def main():
    """ä¸»å‡½æ•¸"""
    print("="*80)
    print("ğŸ” ç¶œåˆèšé¡ç®—æ³•æ¯”è¼ƒåˆ†æ")
    print("="*80)
    
    # å‰µå»ºæ¯”è¼ƒè¡¨æ ¼
    comparison_df = create_comprehensive_comparison()
    
    print("\nğŸ“Š ç¶œåˆæ¯”è¼ƒè¡¨æ ¼:")
    print("-" * 80)
    print(comparison_df.to_string(index=False))
    
    # å„²å­˜è¡¨æ ¼
    comparison_df.to_csv('comprehensive_clustering_comparison.csv', index=False, encoding='utf-8')
    print(f"\nğŸ’¾ è©³ç´°æ¯”è¼ƒè¡¨æ ¼å·²å„²å­˜: comprehensive_clustering_comparison.csv")
    
    # ç”Ÿæˆæ¨è–¦
    generate_recommendations(comparison_df)
    
    print("\n" + "="*80)
    print("âœ¨ åˆ†æå®Œæˆï¼å»ºè­°ä½¿ç”¨è©•åˆ†æœ€é«˜çš„ç®—æ³•ã€‚")
    print("="*80)

if __name__ == "__main__":
    main() 